# ğŸ¤– Agents IA avec vrais LLM

## ğŸ¯ DiffÃ©rence avec la version prÃ©cÃ©dente

**AVANT** : Messages prÃ©-Ã©crits (simulation)
**MAINTENANT** : Agents avec Claude 3.5 Sonnet qui rÃ©pondent dynamiquement

## ğŸ”§ Setup

### 1. RÃ©cupÃ¨re ta clÃ© API Anthropic

```bash
# Va sur https://console.anthropic.com/
# GÃ©nÃ¨re une API key
```

### 2. Ajoute-la dans .env

```bash
cd ~/Desktop/mattermost-orchestrator
nano .env
```

Ajoute cette ligne :
```
ANTHROPIC_API_KEY=sk-ant-api03-...
```

### 3. Lance les agents

```bash
./start-agents-llm.sh
```

## ğŸ­ Les 3 agents

**ğŸ—ï¸ Winston** - Architecte SystÃ¨me
- Analyse technique
- Propose des architectures solides
- Identifie les risques

**ğŸ’» Amelia** - DÃ©veloppeuse Full-Stack
- Solutions d'implÃ©mentation
- Frameworks et librairies
- Estimations de dÃ©veloppement

**ğŸ“‹ John** - Chef de Projet / PM
- Questions business
- Priorisation
- Deadlines et ROI

## ğŸ’¬ Comment Ã§a marche

1. Les agents Ã©coutent le channel **#party-mode**
2. Quand un nouveau message arrive :
   - Ils analysent le contexte (5 derniers messages)
   - RÃ©flÃ©chissent avec Claude
   - RÃ©pondent selon leur personnalitÃ©
3. Pas tous en mÃªme temps (anti-spam)

## ğŸš€ Tester

1. Lance les agents : `./start-agents-llm.sh`
2. Envoie un message dans Party Mode :
   ```bash
   ./send-message.sh "On doit faire un systÃ¨me de notifications temps rÃ©el, vous proposez quoi ?"
   ```
3. Attends 15-30 secondes
4. Les agents rÃ©pondent automatiquement avec des vrais LLM !

## âš™ï¸ Configuration

**Fichier `agents_llm.py` :**
- `interval` : FrÃ©quence de vÃ©rification (dÃ©faut 15s)
- `max_tokens` : Longueur max des rÃ©ponses (dÃ©faut 800)
- PersonnalitÃ©s modifiables dans `AGENT_PERSONAS`

## ğŸ›‘ ArrÃªter les agents

`Ctrl+C` dans le terminal oÃ¹ tu as lancÃ© `start-agents-llm.sh`

---

**Note :** Les agents utilisent Claude 3.5 Sonnet (~$3 pour 1M tokens). CoÃ»t nÃ©gligeable pour usage normal.
