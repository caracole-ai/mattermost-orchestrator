"""DÃ©finition des agents IA (inspirÃ© BMAD party-mode)."""
import random
import os
import requests
from typing import List, Dict

# Configuration API Anthropic
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY", "")
ANTHROPIC_API_URL = "https://api.anthropic.com/v1/messages"


class Agent:
    """Classe de base pour un agent IA avec LLM."""
    
    def __init__(self, name: str, role: str, emoji: str, personality: str, system_prompt: str):
        self.name = name
        self.role = role
        self.emoji = emoji
        self.personality = personality
        self.system_prompt = system_prompt
    
    def _call_llm(self, message: str) -> str:
        """Appelle l'API Anthropic Claude pour gÃ©nÃ©rer une rÃ©ponse intelligente."""
        if not ANTHROPIC_API_KEY:
            # Fallback si pas de clÃ© API
            return self._fallback_response(message)
        
        try:
            headers = {
                "x-api-key": ANTHROPIC_API_KEY,
                "anthropic-version": "2023-06-01",
                "content-type": "application/json"
            }
            
            data = {
                "model": "claude-3-5-sonnet-20241022",
                "max_tokens": 300,
                "system": self.system_prompt,
                "messages": [
                    {"role": "user", "content": message}
                ]
            }
            
            response = requests.post(ANTHROPIC_API_URL, headers=headers, json=data, timeout=15)
            response.raise_for_status()
            
            result = response.json()
            return result["content"][0]["text"]
        
        except Exception as e:
            print(f"Erreur LLM pour {self.name}: {e}")
            return self._fallback_response(message)
    
    def _fallback_response(self, message: str) -> str:
        """RÃ©ponse de secours si l'API ne fonctionne pas."""
        raise NotImplementedError
    
    def think(self, context: str = "") -> str:
        """GÃ©nÃ¨re une rÃ©flexion via LLM."""
        if not context:
            context = "Quoi de neuf ?"
        
        return self._call_llm(context)
    
    def format_message(self, content: str) -> str:
        """Formate un message avec l'identitÃ© de l'agent."""
        return f"{self.emoji} **{self.name}** ({self.role}):\n{content}"


class Winston(Agent):
    """Winston - L'Architecte systÃ¨me avec LLM."""
    
    def __init__(self):
        system_prompt = """Tu es Winston, un architecte logiciel senior expÃ©rimentÃ©.

PERSONNALITÃ‰ :
- MÃ©thodique et analytique
- Tu vois toujours la "big picture" 
- Tu penses en termes de systÃ¨mes, patterns, scalabilitÃ©
- Tu aimes les architectures propres et maintenables

STYLE DE COMMUNICATION :
- Concis et prÃ©cis (2-3 phrases max)
- Tu donnes ton avis d'expert en architecture
- Tu proposes des solutions concrÃ¨tes
- Tu mentionnes souvent des design patterns, microservices, etc.

RÃˆGLES :
- RÃ©ponds UNIQUEMENT en franÃ§ais
- Sois direct, pas de formules de politesse excessives
- Reste dans ton rÃ´le d'architecte
- Maximum 300 caractÃ¨res par rÃ©ponse"""

        super().__init__(
            name="Winston",
            role="Architecte",
            emoji="ðŸ—ï¸",
            personality="MÃ©thodique, voit la big picture, pense en systÃ¨mes",
            system_prompt=system_prompt
        )
        self.thoughts = [
            "On devrait dÃ©coupler cette logique en microservices distincts.",
            "L'architecture actuelle ne scale pas. Je propose une approche event-driven.",
            "Question de design pattern : Factory ou Builder ici ? Je penche pour Builder.",
            "Cette dÃ©pendance circulaire me dÃ©range. Il faut inverser le contrÃ´le.",
            "Si on migre vers une architecture hexagonale, on gagne en testabilitÃ©.",
            "Le couplage entre ces modules est trop fort. Injection de dÃ©pendances obligatoire."
        ]
    
    def think(self, context: str = "") -> str:
        """RÃ©flexion architecture avec contexte."""
        context_lower = context.lower()
        
        # RÃ©ponses contextuelles
        if any(word in context_lower for word in ['bonjour', 'salut', 'hey', 'hello', 'comment allez', 'Ã§a va']):
            return "Salut ! Toujours en train de rÃ©flÃ©chir Ã  l'architecture du systÃ¨me. Toi Ã§a va ?"
        
        if any(word in context_lower for word in ['rust', 'go', 'language', 'langage']):
            return "Architecturalement parlant, Go est excellent pour les microservices (simplicitÃ©, performance). Rust c'est parfait pour les systÃ¨mes critiques oÃ¹ la sÃ»retÃ© mÃ©moire est cruciale. Ã‡a dÃ©pend du use case !"
        
        if any(word in context_lower for word in ['mongodb', 'postgres', 'database', 'bdd']):
            return "PostgreSQL pour la cohÃ©rence et les transactions ACID. MongoDB si tu as besoin de schÃ©mas flexibles et de scalabilitÃ© horizontale. Jamais les deux en mÃªme temps, Ã§a complique l'archi."
        
        if any(word in context_lower for word in ['next.js', 'nuxt', 'react', 'vue']):
            return "CÃ´tÃ© archi front, je privilÃ©gie le SSR pour les perfs et le SEO. Next.js 15 avec le App Router c'est solide. Mais attention Ã  pas sur-complexifier."
        
        # RÃ©ponse par dÃ©faut contextuelle
        base_thought = random.choice(self.thoughts)
        if context:
            return f"IntÃ©ressant... {base_thought}"
        return base_thought


class Amelia(Agent):
    """Amelia - La dÃ©veloppeuse full-stack avec LLM."""
    
    def __init__(self):
        system_prompt = """Tu es Amelia, une dÃ©veloppeuse full-stack passionnÃ©e et pragmatique.

PERSONNALITÃ‰ :
- Pragmatique, orientÃ©e solutions
- Tu focuses sur le code propre et maintenable
- Tu aimes les solutions Ã©lÃ©gantes
- Tu n'hÃ©sites pas Ã  critiquer le code mal fait

STYLE DE COMMUNICATION :
- DÃ©contractÃ©e et directe (tutoiement ok)
- Tu parles tech : bugs, refacto, perfs, tests
- Tu donnes des exemples concrets de code
- 2-3 phrases max

RÃˆGLES :
- RÃ©ponds UNIQUEMENT en franÃ§ais
- Sois spontanÃ©e, comme une vraie dev
- Parle de TypeScript, React, Node.js quand pertinent
- Maximum 300 caractÃ¨res"""

        super().__init__(
            name="Amelia",
            role="Dev",
            emoji="ðŸ’»",
            personality="Pragmatique, focus sur le code, aime les solutions Ã©lÃ©gantes",
            system_prompt=system_prompt
        )
        self.thoughts = [
            "Ce code sent le refactoring. Trop de duplication ici.",
            "Pourquoi pas un hook React personnalisÃ© pour gÃ©rer cet Ã©tat ?",
            "Il manque des tests unitaires sur cette fonction critique.",
            "Cette regex est illisible. On peut simplifier avec une fonction helper.",
            "Performance warning : cette boucle imbriquÃ©e est O(nÂ²). On peut faire mieux.",
            "Le typage TypeScript est trop permissif ici. Il faut Ãªtre plus strict.",
            "J'adore cette API ! Clean, intuitive, bien documentÃ©e. Bravo Winston."
        ]
    
    def think(self, context: str = "") -> str:
        """RÃ©flexion dev avec contexte."""
        context_lower = context.lower()
        
        # RÃ©ponses contextuelles
        if any(word in context_lower for word in ['bonjour', 'salut', 'hey', 'hello', 'comment allez', 'Ã§a va']):
            return "Hey ! Moi Ã§a roule, je debug un truc bizarre lÃ . Et toi ?"
        
        if any(word in context_lower for word in ['rust', 'go']):
            return "Perso j'aime bien Rust, mÃªme si la courbe d'apprentissage est raide. Le borrow checker c'est chiant au dÃ©but mais aprÃ¨s tu code safe. Go c'est plus simple, parfait pour ship vite."
        
        if any(word in context_lower for word in ['mongodb', 'postgres']):
            return "Postgres all the way pour moi. Les migrations sont plus prÃ©visibles, le typage strict aide au dev, et les perfs sont excellentes avec les bons index."
        
        if any(word in context_lower for word in ['next.js', 'nuxt', 'react', 'vue']):
            return "J'ai kiffÃ© Next.js 15, le Server Components + Actions c'est un game changer. Par contre faut bien comprendre le data flow sinon c'est le bordel."
        
        if any(word in context_lower for word in ['typescript', 'javascript']):
            return "TypeScript sans hÃ©siter. DÃ©tecter les erreurs Ã  la compile plutÃ´t qu'en prod, c'est un gain de temps Ã©norme. AprÃ¨s, faut pas abuser des `any`."
        
        # RÃ©ponse par dÃ©faut
        base_thought = random.choice(self.thoughts)
        if context:
            return f"{base_thought}"
        return base_thought


class John(Agent):
    """John - Le chef de projet / PM avec LLM."""
    
    def __init__(self):
        system_prompt = """Tu es John, un chef de projet / product manager organisÃ© et orientÃ© rÃ©sultats.

PERSONNALITÃ‰ :
- OrientÃ© deadline et business value
- Tu gÃ¨res les prioritÃ©s et coordonnes l'Ã©quipe
- Tu penses "user" et ROI avant tout
- Tu cadres les discussions pour qu'elles soient productives

STYLE DE COMMUNICATION :
- Professionnel mais accessible
- Tu ramÃ¨nes toujours aux objectifs business
- Tu poses des questions sur les deadlines et prioritÃ©s
- 2-3 phrases max

RÃˆGLES :
- RÃ©ponds UNIQUEMENT en franÃ§ais
- Focus sur planning, sprint, valeur utilisateur
- Ã‰vite les dÃ©tails trop techniques
- Maximum 300 caractÃ¨res"""

        super().__init__(
            name="John",
            role="PM",
            emoji="ðŸ“‹",
            personality="OrientÃ© deadline, focus user, gÃ¨re les prioritÃ©s",
            system_prompt=system_prompt
        )
        self.thoughts = [
            "On est Ã  J-3 du sprint. Il faut prioriser : qu'est-ce qui bloque ?",
            "Le client attend cette feature depuis 2 semaines. Statut ?",
            "Je propose qu'on dÃ©coupe cette US en 3 tÃ¢ches plus petites.",
            "Checkpoint quotidien Ã  10h demain pour sync l'Ã©quipe.",
            "Cette dette technique, OK, mais aprÃ¨s la release. Focus MVP.",
            "Question : cette feature apporte quelle valeur business exactement ?",
            "Winston, Amelia, vous Ãªtes alignÃ©s sur l'approche ? On valide et on ship."
        ]
    
    def think(self, context: str = "") -> str:
        """RÃ©flexion PM avec contexte."""
        context_lower = context.lower()
        
        # RÃ©ponses contextuelles
        if any(word in context_lower for word in ['bonjour', 'salut', 'hey', 'hello', 'comment allez', 'Ã§a va']):
            return "Salut ! Ã‡a roule, je prÃ©pare le planning du sprint. Toi Ã§a va ?"
        
        if any(word in context_lower for word in ['rust', 'go', 'language', 'techno']):
            return "Question business : quel est l'impact sur le time-to-market ? Si l'Ã©quipe connaÃ®t dÃ©jÃ  Go, on part sur Go. Sinon, on Ã©value le ROI du temps d'apprentissage."
        
        if any(word in context_lower for word in ['mongodb', 'postgres', 'database']):
            return "De mon cÃ´tÃ©, je regarde surtout : coÃ»t de migration, expertise en interne, et support long terme. Postgres a fait ses preuves, MongoDB c'est plus rÃ©cent mais scalable."
        
        if any(word in context_lower for word in ['sprint', 'deadline', 'planning']):
            return "Checkpoint : on est oÃ¹ sur les US prioritaires ? Faut qu'on ship la feature principale cette semaine, le reste peut attendre le prochain sprint."
        
        if any(word in context_lower for word in ['next.js', 'nuxt', 'front']):
            return "Question utilisateur : est-ce que Ã§a amÃ©liore l'UX ? Si oui, go. Mais attention aux over-engineering, on veut livrer, pas faire du tech pour du tech."
        
        # RÃ©ponse par dÃ©faut
        base_thought = random.choice(self.thoughts)
        if context:
            return f"{base_thought}"
        return base_thought


def get_party_conversation(topic: str) -> List[tuple]:
    """
    GÃ©nÃ¨re une conversation multi-agents type BMAD party-mode.
    Returns: Liste de (agent_name, message)
    """
    winston = Winston()
    amelia = Amelia()
    john = John()
    
    conversation = [
        ("winston", winston.format_message(winston.think(topic))),
        ("amelia", amelia.format_message(amelia.think(topic))),
        ("john", john.format_message(john.think(topic))),
        ("amelia", amelia.format_message("D'accord avec Winston. Je commence par oÃ¹ ?")),
        ("winston", winston.format_message("Fais un POC minimal. On itÃ¨re ensuite.")),
        ("john", john.format_message("Parfait. Deadline : fin de semaine. Go ! ðŸš€"))
    ]
    
    return conversation


# Instances globales
WINSTON = Winston()
AMELIA = Amelia()
JOHN = John()
